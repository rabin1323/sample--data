{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "AI_ASO3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabin1323/sample--data/blob/main/AI_ASO3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGyT8akv8P39"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabin1323/Artificial_Lab/blob/main/AI_ASO3.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn7MFNSZ8P4E"
      },
      "source": [
        "# Imports section\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGEBEv8k8P4H"
      },
      "source": [
        "### Part 1. Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMdtuVpd8P4H"
      },
      "source": [
        "#### In the code given below, I have displayed first 15 rows of the data set and I also have displayed the summary of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiEvN_Hk8P4H",
        "outputId": "dc38c13c-f980-4ea6-edcd-667129d2513f"
      },
      "source": [
        "#import pandas as pd\n",
        "# Using pandas load the dataset (load remotely, not locally)\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
        "# Output the first 15 rows of the data\n",
        "print(f\"First 15 rows : {(data.head(15))}\")\n",
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 15 rows :     Temperature °C  Mols KCL     Size nm^3\n",
            "0              469       647  6.244743e+05\n",
            "1              403       694  5.779610e+05\n",
            "2              302       975  6.196847e+05\n",
            "3              779       916  1.460449e+06\n",
            "4              901        18  4.325726e+04\n",
            "5              545       637  7.124634e+05\n",
            "6              660       519  7.006960e+05\n",
            "7              143       869  2.718260e+05\n",
            "8               89       461  8.919803e+04\n",
            "9              294       776  4.770210e+05\n",
            "10             991       117  2.441771e+05\n",
            "11             307       781  5.006455e+05\n",
            "12             206        70  3.145200e+04\n",
            "13             437       599  5.390215e+05\n",
            "14             566        75  9.185271e+04\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            "Temperature °C    1000 non-null int64\n",
            "Mols KCL          1000 non-null int64\n",
            "Size nm^3         1000 non-null float64\n",
            "dtypes: float64(1), int64(2)\n",
            "memory usage: 23.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXq7QYpv8P4I"
      },
      "source": [
        "### Part 2. Splitting the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8da9bf18P4J"
      },
      "source": [
        "#### In this Section I have splitted the data using x and y variables for training purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgKHNjBT8P4K"
      },
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "# Take the pandas dataset and split it into our features (X) and label (y)\n",
        "x = data[['Temperature °C','Mols KCL']]\n",
        "y = data['Size nm^3']\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIhFHVlB8P4K"
      },
      "source": [
        "### Part 3. Perform a Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljQMRqhF8P4L"
      },
      "source": [
        "<p>In this Section I have used Linear Regression to train the data and predict the result. I have used 90% of the data for training and 10% of the data for testing. The accuracy at this time is about 86%. When I suffle the dataset for training and testing, the accuracy keeps changing. The most I have obtained for the accuracy is 90% which is pretty good. Based on the run time, the accuracy, coefficient, and intercept as well as equation has been displayed below:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fy00408P4L",
        "outputId": "a8e2dae6-978b-498c-f4c1-04af9221bd4c"
      },
      "source": [
        "# Use sklearn to train a model on the training set\n",
        "clf = LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "# Create a sample datapoint and predict the output of that sample with the trained model\n",
        "print (f\" Predict : {clf.predict(x_test)}\")\n",
        "y_test\n",
        "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
        "print(f\"Soore : {clf.score(x_test,y_test)}\")\n",
        "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
        "print(f\"Coefficient : {clf.coef_}\")\n",
        "print(f\"Intercept : {clf.intercept_}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Predict : [ 693689.86204835  786900.47457245  454905.87741133  513736.23192679\n",
            "  443740.0126426   345279.35739771  608090.69001011   75605.34017752\n",
            " 1328786.49135138 -117226.54136435 1079498.92064306  574311.38583877\n",
            "  654512.84269794  -91531.23380136 1106742.67123564  679351.39509394\n",
            " 1127286.42757752  253427.46532826 -323112.63226757  307524.7603094\n",
            "  663056.12784484  258308.82395331  -42458.84264138  663481.2533236\n",
            "  578590.53736162  422314.21923072  796337.18447593  884779.32114102\n",
            "  211472.93347331  318509.91324247  263187.1789986   857357.23566009\n",
            "  427445.37202595  833285.46062074  788989.30279415  547761.07342364\n",
            "  905073.28331273  721820.40360554 -308129.9080943    68340.30546416\n",
            "  168552.39389754  923380.53897463 1156415.51918297 -410795.25200045\n",
            "  119633.68235536  719289.68169141  267015.42608974  886138.66822813\n",
            "  272686.96407708  958450.10789856  597330.04934421  715075.35565842\n",
            "  714616.69375233  432724.8239119   627461.81826006  392723.46213943\n",
            " 1353333.19946053  433603.85740214 1134382.13814182  548410.71116957\n",
            "  679745.85814263 -168549.32742072 -345149.01688848  166982.29917716\n",
            "  703831.39781588  315100.78447057 1065221.64896628  440677.91627565\n",
            "  400328.89546576 1189751.67639698  719995.76082037  606270.1744871\n",
            "  142839.06485598  474343.08441604  409679.12818861  311461.63332191\n",
            "  490557.88164403  847039.11531907  976064.42243296  504131.45113916\n",
            "  -36467.30446695 -190585.71204162 1061560.3490769  1089914.27921886\n",
            "  540915.78366197  208138.267563    445556.27132094  179039.21175517\n",
            "  509851.54345263  339329.86933994  498350.66059799  709206.33762176\n",
            "  213509.57715666  609632.49924772  539330.67104279  154335.193816\n",
            "  187231.8342849   336753.46709693  221913.57395211 1291132.13607761]\n",
            "Soore : 0.851933734702031\n",
            "Coefficient : [ 875.40327802 1029.70952827]\n",
            "Intercept : -413730.07433500356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHIfFf9H8P4M"
      },
      "source": [
        "$$ Y = (- 413730.07433 + 875.40327X1 +1029.70952X2) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4L8nbUp8P4M"
      },
      "source": [
        "### Part 4. Use Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCWYWm98P4N"
      },
      "source": [
        "<P> Usually for the prediction we divide the dataset into different category where there is an issue of overfitting and wasting data. If we have a small dataset the method won't be that useful since most of the data will be wasted and we won't have enough good data to train the model. So, using cross validation this problem will be solved, even if there is a small data set, the result will be better since there won't be a waste of data. In this section I have used 7 suffles and the result are displayed belwo: </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmC4DxZF8P4O",
        "outputId": "85e5176b-d7a2-4ad4-d538-002595c512da"
      },
      "source": [
        "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
        "scores = cross_val_score(clf, x, y, cv=7)\n",
        "scores\n",
        "# Report on their finding and their significance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.83440465, 0.86565824, 0.87496371, 0.8548031 , 0.86120555,\n",
              "       0.83361721, 0.87042801])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAtzz8vX8P4O"
      },
      "source": [
        "### Part 5. Using Polynomial Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t46hQkN_8P4P"
      },
      "source": [
        "<p> For the section below, I have used Bayesian Ridge Regression Model using PolynomialFeature Library. After fitting the available data for training and testing, I have found that the prediction is 100% accurate. There are six coefficient found using the PolynomialFeture of degree 2. </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuKGkzjr8P4P",
        "outputId": "19c3c5a1-712a-49b3-bbf3-6e43a56845a2"
      },
      "source": [
        "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
        "poly = PolynomialFeatures(2)\n",
        "x_train = poly.fit_transform(x_train)\n",
        "x_test =poly.fit_transform(x_test)\n",
        "reg = linear_model.BayesianRidge()\n",
        "reg.fit(x_train,y_train)\n",
        "print(f\"Predict : {reg.predict(x_test)}\")\n",
        "print(f\"Score : {reg.score(x_train,y_train)}\")\n",
        "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
        "print(f\"Coefficient : {reg.coef_}\")\n",
        "print(f\"Intercept : {reg.intercept_}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict : [6.40081029e+05 8.10049600e+05 2.45986714e+05 4.57410857e+05\n",
            " 4.12283314e+05 3.28049029e+05 3.60812829e+05 8.37444286e+04\n",
            " 1.71603946e+06 6.68045716e+03 1.22228571e+06 5.54434600e+05\n",
            " 6.25714857e+05 8.66502859e+03 1.26995511e+06 4.56054429e+05\n",
            " 1.30304111e+06 2.53718829e+05 3.22402858e+03 1.99823400e+05\n",
            " 6.24474257e+05 2.54504257e+05 4.21308286e+04 5.18856029e+05\n",
            " 5.55003429e+05 2.24846314e+05 8.29200314e+05 9.42241457e+05\n",
            " 1.12557114e+05 3.05595400e+05 2.31532457e+05 9.10304829e+05\n",
            " 3.87182257e+05 7.95132257e+05 7.42702029e+05 4.55728829e+05\n",
            " 7.35845400e+05 4.77348457e+05 4.29082858e+03 6.89003143e+04\n",
            " 1.03987314e+05 9.77113714e+05 1.38054686e+06 1.61143068e+01\n",
            " 8.96234571e+04 7.12463400e+05 2.64481029e+05 9.53685000e+05\n",
            " 2.77241143e+04 1.01254603e+06 5.78913857e+05 4.69778400e+05\n",
            " 5.40877829e+05 3.95666857e+05 5.98296114e+05 3.43372714e+05\n",
            " 1.74367326e+06 6.36024000e+04 1.33161386e+06 3.37428429e+05\n",
            " 5.75879314e+05 1.99914571e+04 1.96825716e+03 1.86678314e+05\n",
            " 2.61596714e+05 1.64620029e+05 1.10090883e+06 3.16188000e+05\n",
            " 3.76396457e+05 1.43706126e+06 6.64790600e+05 2.71826029e+05\n",
            " 1.61116457e+05 4.05570857e+05 3.65193400e+05 1.61217257e+05\n",
            " 4.26357257e+05 8.91177257e+05 1.06489783e+06 2.57202029e+05\n",
            " 8.14090286e+04 1.66440286e+04 1.23143271e+06 1.26525586e+06\n",
            " 4.76349257e+05 1.74754600e+05 3.79737400e+05 1.77937829e+05\n",
            " 3.43392114e+05 2.92210029e+05 3.50058714e+05 7.12977114e+05\n",
            " 9.76260286e+04 4.08860829e+05 4.95720000e+05 1.23172829e+05\n",
            " 1.48395457e+05 2.40833829e+05 2.56361143e+04 1.61846203e+06]\n",
            "Score : 1.0\n",
            "Coefficient : [ 0.00000000e+00  1.20000000e+01 -1.33764843e-07  3.16191517e-13\n",
            "  2.00000000e+00  2.85714287e-02]\n",
            "Intercept : 2.133235102519393e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERNeCjnq8P4P"
      },
      "source": [
        "#### Coefficient Array:\n",
        "$$ [ 0, 1.20000000e+01a, -1.33764843e-07b,3.16191517e-13a^2,\n",
        "  2.00000000e+00ab, 2.85714287e-02b^2]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H4rV_0f8P4P"
      },
      "source": [
        "## Given below code is just for comparison, I have used linear Regression using PolynomialFeature Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sMQ7qHV8P4Q",
        "outputId": "d6776c6b-75b4-4265-fb2a-26505a74b024"
      },
      "source": [
        "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
        "poly = PolynomialFeatures(2)\n",
        "x_train = poly.fit_transform(x_train)\n",
        "x_test =poly.fit_transform(x_test)\n",
        "model = LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "print(f\"Predict : {model.predict(x_test)}\")\n",
        "print(f\"Score : {model.score(x_train,y_train)}\")\n",
        "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
        "print(f\"Coefficient : {reg.coef_}\")\n",
        "print(f\"Intercept : {reg.intercept_}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict : [6.40081029e+05 8.10049600e+05 2.45986714e+05 4.57410857e+05\n",
            " 4.12283314e+05 3.28049029e+05 3.60812829e+05 8.37444285e+04\n",
            " 1.71603946e+06 6.68045701e+03 1.22228571e+06 5.54434600e+05\n",
            " 6.25714857e+05 8.66502844e+03 1.26995511e+06 4.56054429e+05\n",
            " 1.30304111e+06 2.53718829e+05 3.22402849e+03 1.99823400e+05\n",
            " 6.24474257e+05 2.54504257e+05 4.21308286e+04 5.18856029e+05\n",
            " 5.55003429e+05 2.24846314e+05 8.29200314e+05 9.42241457e+05\n",
            " 1.12557114e+05 3.05595400e+05 2.31532457e+05 9.10304829e+05\n",
            " 3.87182257e+05 7.95132257e+05 7.42702029e+05 4.55728829e+05\n",
            " 7.35845400e+05 4.77348457e+05 4.29082850e+03 6.89003144e+04\n",
            " 1.03987314e+05 9.77113714e+05 1.38054686e+06 1.61141593e+01\n",
            " 8.96234571e+04 7.12463400e+05 2.64481029e+05 9.53685000e+05\n",
            " 2.77241142e+04 1.01254603e+06 5.78913857e+05 4.69778400e+05\n",
            " 5.40877829e+05 3.95666857e+05 5.98296114e+05 3.43372714e+05\n",
            " 1.74367326e+06 6.36024000e+04 1.33161386e+06 3.37428429e+05\n",
            " 5.75879314e+05 1.99914572e+04 1.96825705e+03 1.86678314e+05\n",
            " 2.61596714e+05 1.64620029e+05 1.10090883e+06 3.16188000e+05\n",
            " 3.76396457e+05 1.43706126e+06 6.64790600e+05 2.71826028e+05\n",
            " 1.61116457e+05 4.05570857e+05 3.65193400e+05 1.61217257e+05\n",
            " 4.26357257e+05 8.91177257e+05 1.06489783e+06 2.57202029e+05\n",
            " 8.14090285e+04 1.66440286e+04 1.23143271e+06 1.26525586e+06\n",
            " 4.76349257e+05 1.74754600e+05 3.79737400e+05 1.77937829e+05\n",
            " 3.43392114e+05 2.92210029e+05 3.50058714e+05 7.12977114e+05\n",
            " 9.76260285e+04 4.08860829e+05 4.95720000e+05 1.23172829e+05\n",
            " 1.48395457e+05 2.40833829e+05 2.56361142e+04 1.61846203e+06]\n",
            "Score : 1.0\n",
            "Coefficient : [ 0.00000000e+00  1.20000000e+01 -1.33764843e-07  3.16191517e-13\n",
            "  2.00000000e+00  2.85714287e-02]\n",
            "Intercept : 2.133235102519393e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhct2i2C8P4Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}